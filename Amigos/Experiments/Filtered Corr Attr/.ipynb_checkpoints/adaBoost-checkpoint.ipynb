{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "import sklearn as skl\n",
    "from sklearn import tree\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report \n",
    "%matplotlib inline\n",
    "import time\n",
    "import warnings\n",
    "from sklearn import model_selection\n",
    "# 5-class classification version\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = r'D:\\CIC\\Train and Test\\Filter Corr Attr'\n",
    "# Load all the training and testing data\n",
    "X_train = pd.read_pickle(f'{data_root_dir}\\X_train.pkl')\n",
    "X_test = pd.read_pickle(f'{data_root_dir}\\X_test.pkl')\n",
    "y_test = pd.read_pickle(f'{data_root_dir}\\y_test.pkl')\n",
    "y_train = pd.read_pickle(f'{data_root_dir}\\y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer to see how long it takes to test the algorithm\n",
    "startTime = time.perf_counter()\n",
    "\n",
    "\n",
    "# 'n_estimators' is equal to the numebr of trees\n",
    "adaBoost1 = AdaBoostClassifier(n_estimators=100)\n",
    "adaBoost1.fit(X_train, y_train)\n",
    "\n",
    "predictions = adaBoost1.predict(X_test)\n",
    "confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Print endTime - startTime to calculate how long it takes\n",
    "endTime = time.perf_counter()\n",
    "\n",
    "print(f\"Total time: {endTime - startTime:0.4f} seconds \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = confusion_matrix(y_test, predictions)\n",
    "error = zero_one_loss(y_test, predictions)\n",
    "score = accuracy_score(y_test, predictions) * 100\n",
    "report = classification_report(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time: {endTime - startTime:0.4f} seconds \\n\")\n",
    "print(\"AdaBoost Classifier Results\")\n",
    "print(\"=================================================\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"{results[0]}\")\n",
    "print(f\"{results[1]} \\n\")\n",
    "\n",
    "print(\"Report :\")\n",
    "print(report) \n",
    "\n",
    "print(f\"True Postive   : {results[0][0]}\")\n",
    "print(f\"False Positive : {results[0][1]}\")\n",
    "print(f\"False Negative : {results[1][0]}\")\n",
    "print(f\"True Negative  : {results[1][1]}\")\n",
    "print(f\"Error Value    : {error}\")\n",
    "print(f\"Accuracy_Score : {score}\")\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(adaBoost1.feature_importances_, index=X_test.columns)\n",
    "print('Feature importances sorted:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 20 features:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nlargest(20).plot(kind='barh', figsize=(10,10))\n",
    "print(feature_importances.nlargest(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Least 20 features:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nsmallest(20).plot(kind='barh', figsize=(10,10))\n",
    "print(feature_importances.nsmallest(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
