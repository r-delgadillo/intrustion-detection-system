{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "import sklearn as skl\n",
    "from sklearn import tree\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report \n",
    "%matplotlib inline\n",
    "import time\n",
    "import warnings\n",
    "# 5-class classification version\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss, accuracy_score\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = r'D:\\CIC\\Train and Test\\Filter 40 - DT'\n",
    "# Load all the training and testing data\n",
    "X_train = pd.read_pickle(f'{data_root_dir}\\X_train.pkl')\n",
    "X_test = pd.read_pickle(f'{data_root_dir}\\X_test.pkl')\n",
    "y_test = pd.read_pickle(f'{data_root_dir}\\y_test.pkl')\n",
    "y_train = pd.read_pickle(f'{data_root_dir}\\y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer to see how long it takes to test the algorithm\n",
    "startTime = time.perf_counter()\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=10)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "dt_results = confusion_matrix(y_test, y_pred_dt)\n",
    "dt_error = zero_one_loss(y_test, y_pred_dt)\n",
    "dt_score = accuracy_score(y_test, y_pred_dt) * 100\n",
    "dt_report = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "# Print endTime - startTime to calculate how long it takes\n",
    "endTime = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total time: {endTime - startTime:0.4f} seconds \\n\")\n",
    "print(\"Decision Tree Classifier Results\")\n",
    "print(\"=================================================\")\n",
    "print(f\"Confusion Matrix:\")\n",
    "print(f\"{dt_results[0]}\")\n",
    "print(f\"{dt_results[1]} \\n\")\n",
    "\n",
    "print(\"Report :\")\n",
    "print(dt_report) \n",
    "\n",
    "print(f\"True Postive   : {dt_results[0][0]}\")\n",
    "print(f\"False Positive : {dt_results[0][1]}\")\n",
    "print(f\"False Negative : {dt_results[1][0]}\")\n",
    "print(f\"True Negative  : {dt_results[1][1]}\")\n",
    "print(f\"Error Value    : {dt_error}\")\n",
    "print(f\"Accuracy_Score : {dt_score}\")\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(dt_classifier.feature_importances_, index=X_test.columns)\n",
    "print('Feature importances sorted:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nlargest(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 20 features:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nlargest(20).plot(kind='barh', figsize=(10,10))\n",
    "print(feature_importances.nlargest(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Least 20 features:')\n",
    "print('---------------------------------')\n",
    "feature_importances.nsmallest(20).plot(kind='barh', figsize=(10,10))\n",
    "print(feature_importances.nsmallest(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
